# Digital Image Processing: Super Pixels
## Intro
This project is created for the university class named Digital Image Processing at Aristotle University of Thessaloniki (AUTh). It's the first out of three repositories referenced on the same class.

## General
In the second assignment of the course, we will implement the following:

1. Representation of images as graphs.
2. Image segmentation using the graph spectral clustering method (non-recursive).
3. Image segmentation using the normalized cuts method (recursive).
4. Image segmentation using normalized cuts with graph representation based on superpixels from the SLIC method.
   
Along with the assignment, you will find the auxiliary MATLAB file "dip_hw_2.mat," which includes the data we will use for each question, such as input images and affinity matrices.

## Images as Graphs
### Task
Build the routine "Image2Graph" which takes an image with n channels as input and returns the affinity matrix that describes a non-directional graph G = (V, E). More specifically:

function myAffinityMat = Image2Graph(imIn)

Where:
* imIn: The M × N input image with n channels.
* myAffinityMat: The square (and symmetric) affinity matrix describing the graph, with dimensions (M × N) × (M × N).

Consider that each pixel in the image represents a vertex (or node) of the final graph. Additionally, the edge weights of the graph will be calculated as 

A(i,j)= 1/e^(d(i,j)), where d(i,j) is the Euclidean distance of brightness between the i-th and j-th pixel.

The graph generated by the "Image2Graph" routine should be fully-connected, meaning that for each pair of vertices i, j, there should be a corresponding edge e(i, j) with a non-zero weight.

### Implementation
#### Function:
myAffinityMat = Image2Graph(imIn)

#### Arguments:
* imIn: Input image

#### Outputs:
* myAffinityMat: The affinity matrix of the input image
#### Description:
The function calculates the average color difference for each pair of pixels in the original image, taking into account all three RGB colors. It requires the transformation from the one-dimensional array with all points to their coordinates in the original image, where the calculation of m1, n1, and m2, n2 takes place.


#### Function:
myAffinityMat = Image2GraphUpdate(superpixels, colors)

#### Arguments:
* superpixels: Array containing the coordinates of pixels selected as superpixels.
* colors: List containing the color values of the superpixels.
  
#### Outputs:
* myAffinityMat: The affinity matrix of the input image.
  
#### Description:
This function is a variation of the previous one, Image2Graph. The difference is that this specific function takes a list of specific pixels as input, rather than the entire image as in the previous one, but its functionality remains the same.

## Graph Spectral Clustering
### Task
In the second section of the assignment, you will implement the Graph Spectral Clustering method. The steps of the method are described below:
1. Given an input image, construct an undirected graph according to the specifications in Section 1. Let W be the affinity matrix that describes the graph.
2. Calculate the non-normalized Laplacian matrix L as L=D−W, where the diagonal matrix D is defined as: 
D(i,i)=SUMj(W(i,j)). 
3. Solve the generalized eigenvalue problem Lx=λDx and calculate the k smallest eigenvalues and their corresponding eigenvectors.
4. Form the matrix U∈R^(n×k) that contains the eigenvectors u1,...,uk as columns. For i=1,…,n, let yi∈R^(k) be the vector corresponding to the i-th row of U.
5. Cluster the points yi (for i=1,...,n) using the k-means algorithm into clusters C1,...,Ck.

Therefore, create the myGraphSpectralClustering routine that takes as input an affinity matrix describing an undirected graph G=(V,E) and the number of clusters k. It returns the labels of the clusters to which each node of the graph belongs. Specifically:

function clusterIdx = myGraphSpectralClustering(anAffinityMat, k)

Where:
* anAffinityMat: The square (and symmetric) affinity matrix describing the graph.
* k: The number of clusters to be formed.
* clusterIdx: The labels indicating which cluster each node of the graph belongs to.

The unsupervised k-means clustering process should be performed using the MATLAB routine labels = kmeans(X, k), where X is the n × k input matrix (essentially n samples of dimension k), and k is the number of clusters to be formed. The n × 1 vector labels returned by the routine contains the labels of the clusters to which the input samples belong. The calculation of the eigenvectors should be done using the MATLAB routine eigs.

TIP: Carefully study the documentation of the eigs routine (help eigs). The affinity matrices that will be constructed will have large dimensions, so calculating all eigenvectors can be very time-consuming.

1. For the first demo, you are asked to present the functionality of the myGraphSpectralClustering routine. For demo purposes, you will be provided with a pre-constructed affinity matrix (variable d1a in the auxiliary file dip_hw_2.mat). Additionally, since the k-means algorithm involves the random initialization of the k centers as its first step, use the command rng(1) at the beginning of your script to ensure that you can repeat the experiment with the same random seed and, therefore, obtain the same clustering results for the k clusters. Present the labels obtained for the parameters k = 2, k = 3, and k = 4 (a total of 3 experiments). Comment on the results. The above functionalities should be included within the demo1.m script.

2. For demo 2, you are required to present the functionality of myGraphSpectralClustering in combination with the Image2Graph routine. Specifically, in your auxiliary MATLAB file, you are provided with 2 RGB input images named d2a and d2b. Convert each input image into the corresponding graph (i.e., the respective affinity matrix) using Image2Graph and then proceed with the spectral clustering process. Repeat the experiment for the number of centers k = 3 and k = 4 for both images (a total of 4 experiments). Display the results of the clustering process for each input image. Similar to demo 1, use the rng(1) command to control the randomness of the k-means initialization. Comment on the results. The above functionalities should be included within the demo2.m script.

### Implementation
#### Function:
clusterIdx = myGraphSpectralClustering (anAffinityMat, k)

#### Arguments:
* anAffinityMat: The input affinity matrix.
* k: The number of different groups we want to partition the pixels into.

#### Outputs:
* clusterIdx: A list indicating the group of each pixel.
  
#### Description:
First, we define a diagonal matrix with diagonal values equal to the sum of each column of the input matrix. Additionally, we define the Laplacian matrix L exactly as stated in the prompt and find the k eigenvectors corresponding to the k smallest eigenvalues. Finally, we call the kmeans function to obtain the final result, providing it with the eigenvectors we found earlier.

### Results
#### Demo 1
In this demo, we load the pre-made affinity matrix d1a from the data and call the myGraphSpectralClustering function for k=2,3,4. The results are shown in the table below:

![Demo 1](/images/demo1.png)

In the initial experiment (k=2), the clusters are divided into 4 and 8 members, respectively. When k=3, there is a balance as each group has 4 members, while in the case of increasing k again and having 4 groups for separation, this symmetry is lost.

#### Demo 2
First, we read the images from the data and print them together:

![Original image: Colors](/images/original_images/colors.png)
![Original image: Super Mario](/images/original_images/super_mario.png)

Next, we calculate the affinity matrices for the two images (the calculation takes some time), and then the clustering results for the requested cases:

![Colors clustering, k=3](/images/colors_clustering1.png)
![Colors clustering, k=4](/images/colors_clustering2.png)

As shown, the clustering process for the first image is more effective when k=3, as in the case where k=4, there are some points in the fourth class that are misclassified (in this specific image, the groupings are clear in the three different colors).

![Super Mario clustering, k=3](/images/supermario_clustering1.png)
![Super Mario clustering, k=4](/images/supermario_clustering2.png)

The same observation can be made here, as it appears that the pixels in the image are better categorized when k=3. Therefore, we can conclude that an increase in the number of clusters does not necessarily mean an improvement in clustering.

## Normalized cuts
### Task
For this part of the assignment, you will construct the recursive version of the normalized-cuts method for image segmentation.

Regarding the non-recursive version of the method, the steps are common with the five steps of the graph spectral clustering method in section 2. Then, in step 6, the non-recursive version of the n-cuts method progressively merges the k clusters that were created. However, for the purposes of this assignment, we will consider that the non-recursive version of the method ends with the creation of the k clusters (step 5).

The recursive version of the method is a subcase of the non-recursive version with k = 2 (see step 3 above), meaning that each time we divide the graph into 2 pieces. After each partition (steps 1 to 5 with k = 2), we decide whether to continue the partitioning of the specific segments that resulted from the clustering process (specifically, k-means). More specifically, you can make the decision using the following criteria: If the number of nodes labeled 1 or 2 that result is less than a threshold T1 or if the N cut(A, B) value is greater than a threshold T2, then the partitioning of the specific segments stops. Otherwise, each of the two segments resulting from the clustering process is further divided into 2. The process continues recursively and terminates when no segment can be further divided for the reasons mentioned above.

The N cut(A, B) metric for 2 groups of nodes labeled "A" and "B" (or 1 and 0) is defined as follows:

![Ncut equation](/images/ncut.png)

Essentially, the metric assoc(A, V) is the sum of all weights between the nodes belonging to group A (or labeled as 1) and all nodes in the graph (V). The metrics assoc(A, A), assoc(B, V), and assoc(B, B) are defined similarly. We use W to symbolize the affinity matrix.

You need to create the calculateNcut routine, which calculates the relative metric of equation 1 for the 2 groups (clusters) resulting from step 3 of the method. Specifically:

function nCutValue = calculateNcut(anAffinityMat, clusterIdx)

Where:
* anAffinityMat: The square (and symmetric) affinity matrix describing the graph.
* clusterIdx: The labels indicating which of the 2 clusters each graph node belongs to.
* nCutValue: The value of the metric for the 2 groups of nodes.

#### Demo:
In this demo, you are asked to demonstrate the functionality of the calculateNcut routine and present the complete recursive execution of the n-cuts method for image segmentation without a priori determination of segments. Once again, use the images from demo2 (variables d2a and d2b) as input images, and in each case, use the rng(1) command to control the randomness of the experiments.

a. Initially, after constructing the corresponding graphs for the 2 input images, execute the recursive n-cuts method for one step, i.e., split the original graph into 2 pieces (a total of 2 experiments). Show the results of the n-cuts process for one step on each input image, as well as the values of the ncut metrics in each case. Comment on the results of the n-cuts method for one step and the values of the ncut metrics calculated for k = 2. These functions should be included in the demo3a.m script.

b. For the second part of the demo, you are called to present the complete (i.e., recursive) execution of the n-cuts method. Think of the separation process into 2 clusters as the creation of a binary (possibly unbalanced) tree, where each node of the tree holds information about labels in relation to its parent. For example, for the image d2a, you can use threshold values of 0.5 and 0.60 as T1 and T2, respectively. In each case, experimentation with the parameters is recommended.

Show the results of the integrated n-cuts process on each input image. Compare and comment on the results of the recursive n-cuts method in relation to the results obtained from the spectral clustering process and the results of the non-recursive n-cuts method for k = 2 and k = 3. These functions should be included in the demo3b.m script.

### Implementations
#### Function:
nCutValue = calculateNcut(anAffinityMat, clusterIdx)

#### Arguments:
* anAffinityMat: The input affinity matrix.
* clusterIdx: A list containing the group of each pixel in the graph.

#### Outputs:
* nCutValue: The value of the n-cut metric.

#### Description:
The function follows the instructions of the assignment and calculates the number of edges between the vertices of the first group and all the others (variable assocAV). Similarly, the variables assocBV, assocAA, and assocBB are calculated, which are combined, and finally, the value nCutValue defined in the assignment is returned.

#### Function:
final_cluster = recursiveNcut(aff_image, T1, T2)

#### Arguments:
* aff_image: The input affinity matrix.
* T1: A parameter used by the function (explained below).
* T2: A parameter used by the function (explained below).

#### Outputs:
* final_cluster: A list of strings that indicates the group of each pixel involved in the input affinity matrix.

#### Description:
The function was created to perform the recursive n-cuts method. It works efficiently for both input affinity matrices directly derived from image pixels and for matrices describing superpixels. First of all, we divide the graph into 2 groups. We check the number of members in each group, and if it is less than the parameter T1 provided as an argument, then the algorithm performs the segmentation, and the function returns. To achieve the desired segmentation into 10 groups, the function was implemented in such a way that it performs clustering when the number of members is less than the threshold T1 and then returns. Simultaneously, we calculate the value returned by the calculateNcut function and check if it exceeds the value T2. In this case, it returns again after performing the segmentation. In all other cases, we split the groups that have emerged, and each one calls this function again with the same values for the parameters T1 and T2. After all iterations are completed, the function finally returns a binary string for each point given as input initially. This string has a value of 0 in some position if that pixel belonged to group A at that specific recursion step, otherwise, it is assigned the value 1. Here's a demonstration image of the algorithm's operation:

![Recursive Ncut](/images/recursive_ncut.png)

In this random example, the different string values that will be returned are:
[000, 001, 010, 011, 10, 11], meaning a total of 6 groups will be created.
To distinguish between the different values in the output (e.g., 001 vs. 0001), we use the `unique` function, which is already implemented in MATLAB. It returns all the distinct available strings from the `final_cluster` array (this is used in the demo4.m script).

### Results
#### Demo 3a
Essentially, we apply the myGraphSpectralClustering function to each of the two images, with k=2, and calculate the N-Cut values by calling the calculateNcut function. The results are as follows:

![Colors image: Ncut](/images/colors_ncut.png)

The separation appears to be very accurate, as one group consists of all the blue pixels, while the other overlaps with the red and green pixels. The presence of three colors is the reason for the high N-Cut coefficient. Ideally, we would like k=3 as we saw previously: N-Cut = 0.509

![Super mario image: Ncut](/images/supermario_ncut.png)

Similarly here, the function works effectively, and we have an even higher coefficient: N-Cut = 0.785. The value is greater than 0.6, which means it would stop in the recursive resolution, as shown in demo3b.

#### Demo 3b
The above results are from the non-recursive n-cuts method for k=2. For k=3, the following results are obtained:

![Colors image: Compare Ncut](/images/compare_ncut1.png)

As it can be seen, in this simple image, the non-recursive method is more effective compared to the recursive one, as in the latter, some points are clearly grouped incorrectly. For the second image, the following outputs are obtained:

![Super Mario image: Compare Ncut](/images/compare_ncut2.png)

And here, we could say that the non-recursive method is more effective because based on the thresholds requested by the assignment, the recursive method will stop immediately after the first iteration.

## Superpixel Segmentation
### Task
For the last part of the assignment, you will apply the Simple Linear Iterative Clustering (SLIC) method to group the image into superpixels, which will then be divided into segments using the recursive version of the n-cuts method.

A superpixel can be defined as a set of neighboring pixels that share common characteristics, such as similar color or texture features. They provide a convenient and compact representation of an image, which is important for computationally demanding applications. The segmentation of an image into superpixels is usually used as a preprocessing step in image segmentation applications, as this representation captures most of the information in the image and significantly reduces processing time.

To create superpixels, you will apply the Simple Linear Iterative Clustering (SLIC) algorithm, which groups pixels based on color similarity and their proximity in the image. The implementation of SLIC in C is provided by the creators of the method, along with the corresponding MEX function for calling the routine in MATLAB or Octave. You will need to build the MEX files before using the function, as described below:

[labels, ~] = slicmex(imIn, reqNumLabels, cFactor);

Where:
* imIn: The M × N input image with n channels.
* reqNumLabels: The number of desired superpixels. Note that the number of returned superpixels may differ from the requested number.
* cFactor: The superpixel density factor. A higher value makes each superpixel more compact. It takes values in the range [1, 20].
* labels: The M × N output image with 1 channel that corresponds to the superpixel to which each pixel is assigned.

In addition to grouping the image into superpixels, you should also create a routine that calculates the description of each superpixel as the mean color, i.e., the average value of each channel, of all the pixels belonging to that superpixel. Specifically:

function outputImage = superpixelDescriptor(imIn, labels)

Where:
* imIn: The M × N input image with n channels.
* labels: The M × N output image with 1 channel that corresponds to the superpixel to which each pixel is assigned.
* outputImage: The M × N output image with 1 channel that represents the image description for the superpixel to which each pixel belongs.

For the representation as a graph and the computation of the affinity matrix for the image of superpixels, as described by the superpixelDescriptor, you may need to modify the Image2Graph function to accept a list of superpixels instead of a two-dimensional image.

In the final demo of the assignment, you are required to present the integrated image segmentation method for the "bee.jpg" image provided in the assignment. This involves combining the SLIC method for the compressed representation of the image into superpixels with both the recursive and non-recursive n-cuts methods for segmenting the superpixels.

Specifically, for the non-recursive version, you can use values such as k=6 and k=10 as the number of segments. Additionally, you should estimate the threshold values T1 and T2 for the recursive n-cuts method to determine the number of segments chosen in the non-recursive version. For the SLIC method, use the parameter values of 400 for reqNumLabels and 20 for cFactor. In each case, it is recommended to experiment with these parameters.

You should display the results of the integrated segmentation process on the input image and also show the intermediate representation in superpixels according to the color descriptor. Additionally, provide commentary on the difference between the typical n-cuts method applied directly to the input image and the representation in superpixels as a preprocessing step. All of these functionalities should be implemented within the "demo4.m" script.

### Implementations
#### Function:
outputImage = superpixelDescriptor(imIn, labels)

#### Arguments:
* imIn: The input image.
* labels: The labels for each pixel indicating which superpixel it belongs to.

#### Outputs:
* outputImage: The output image, coloring pixels with the same color for each group.

#### Description:
The function is responsible for assigning color to each pixel, taking into account all the
other pixels belonging to the same superpixel. More specifically, we maintain an array of
values for each pixel in an appropriate array, depending on the superpixel it belongs to,
and in the end, we take the average value as the color of all members of the superpixel
and color them accordingly, storing the values in outputImage.

### Results
First, let's briefly describe the functionality of this specific demo. Initially, we read the image from the given file and apply the SLIC algorithm to perform superpixel segmentation. Additionally, we color the image based on the average color of each formed region and, as an example, select a pixel from each region, which is at the midpoint of the (x, y) coordinates of the points belonging to the same region. We calculate the affinity matrix for the selected superpixels and then print the results for the 4 experiments requested in the assignment:

![Bee Image: SLIC algorithm](/images/slic.png)

The segmentation appears to be particularly effective. Now, we will group the superpixels into a total of k=6 segments:

![Bee Image: N-Cut algorithm, k=6](/images/bee_ncut.png)

For the above experiment, the parameters had the values T1=5 and T2=0.1. Next, for k=10:

![Bee Image: N-Cut algorithm, k=10](/images/bee_ncut2.png)

For the above experiment, the parameters had the values T1=3 and T2=0.1. 

An issue arose with the use of the rng(1) option because in the first step, the superpixels are divided into uneven groups, so the range of parameter T1 is necessarily small.
